{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udd01 \u0423\u043b\u0443\u0447\u0448\u0435\u043d\u043d\u044b\u0439 GAN \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043b\u043e\u0433\u0444\u0440\u0435\u0439\u043c-\u043c\u0430\u0442\u0440\u0438\u0446\n", "- \u0420\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u044b\u0439 \u0441\u043b\u043e\u0432\u0430\u0440\u044c\n", "- \u0423\u0433\u043b\u0443\u0431\u043b\u0451\u043d\u043d\u0430\u044f \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 (3 \u0441\u043b\u043e\u044f)\n", "- \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u043d\u043e\u0439 \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b: \u0446\u0435\u043b\u044c, \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u0438\u043d\u0434\u0438\u043a\u0430\u0442\u043e\u0440, \u0440\u0438\u0441\u043a"]}, {"cell_type": "code", "metadata": {}, "source": ["# \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0438 \u0438\u043c\u043f\u043e\u0440\u0442\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import random"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcda \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430\u0440\u044f (\u043e\u043d \u0441\u043e\u0445\u0440\u0430\u043d\u0451\u043d \u0437\u0430\u0440\u0430\u043d\u0435\u0435)"]}, {"cell_type": "code", "metadata": {}, "source": ["# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432\u0440\u0443\u0447\u043d\u0443\u044e \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0438\u0437 \u0444\u0430\u0439\u043b\u0430\n", "vocab = []\n", "with open('/content/gan_vocab_extended.txt', 'r', encoding='utf-8') as f:\n", "    vocab = [line.strip() for line in f.readlines() if line.strip()]\n", "\n", "word2idx = {w: i for i, w in enumerate(vocab)}\n", "idx2word = {i: w for w, i in word2idx.items()}\n", "VOCAB_SIZE = len(vocab)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 \u0413\u043b\u0443\u0431\u043e\u043a\u0430\u044f \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 GAN"]}, {"cell_type": "code", "metadata": {}, "source": ["class Generator(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.model = nn.Sequential(\n", "            nn.Linear(16, 64),\n", "            nn.ReLU(),\n", "            nn.Linear(64, 64),\n", "            nn.ReLU(),\n", "            nn.Linear(64, 4),\n", "        )\n", "    def forward(self, z):\n", "        return self.model(z)\n", "\n", "class Discriminator(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.model = nn.Sequential(\n", "            nn.Linear(4, 64),\n", "            nn.ReLU(),\n", "            nn.Linear(64, 32),\n", "            nn.ReLU(),\n", "            nn.Linear(32, 1),\n", "            nn.Sigmoid()\n", "        )\n", "    def forward(self, x):\n", "        return self.model(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83c\udfcb\ufe0f \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 GAN \u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445"]}, {"cell_type": "code", "metadata": {}, "source": ["gen = Generator()\n", "disc = Discriminator()\n", "loss_fn = nn.BCELoss()\n", "opt_g = optim.Adam(gen.parameters(), lr=0.01)\n", "opt_d = optim.Adam(disc.parameters(), lr=0.01)\n", "\n", "# \u0418\u043d\u0434\u0435\u043a\u0441\u044b \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0448\u0430\u0431\u043b\u043e\u043d\u043e\u0432 (\u043f\u043e 4 \u0431\u043b\u043e\u043a\u0430)\n", "real_data = [\n", "    [0, 6, 12, 18],\n", "    [1, 7, 13, 19],\n", "    [2, 8, 14, 20],\n", "    [3, 9, 15, 21],\n", "    [4, 10, 16, 22],\n", "    [5, 11, 17, 23]\n", "]\n", "\n", "for epoch in range(300):\n", "    for real in real_data:\n", "        real_tensor = torch.tensor(real, dtype=torch.float32)\n", "        pred_real = disc(real_tensor)\n", "        loss_d_real = loss_fn(pred_real, torch.ones(1))\n", "\n", "        noise = torch.randn(16)\n", "        fake = gen(noise)\n", "        pred_fake = disc(fake.detach())\n", "        loss_d_fake = loss_fn(pred_fake, torch.zeros(1))\n", "\n", "        loss_d = loss_d_real + loss_d_fake\n", "        opt_d.zero_grad(); loss_d.backward(); opt_d.step()\n", "\n", "        pred_fake = disc(fake)\n", "        loss_g = loss_fn(pred_fake, torch.ones(1))\n", "        opt_g.zero_grad(); loss_g.backward(); opt_g.step()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udccb \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043b\u043e\u0433\u0444\u0440\u0435\u0439\u043c-\u043c\u0430\u0442\u0440\u0438\u0446\u044b"]}, {"cell_type": "code", "metadata": {}, "source": ["with torch.no_grad():\n", "    z = torch.randn(16)\n", "    generated = gen(z).detach().numpy()\n", "    tokens = [int(abs(i)) % VOCAB_SIZE for i in generated]\n", "    print(\"\\n\u2705 \u0421\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043c\u0430\u0442\u0440\u0438\u0446\u0430:\")\n", "    for i, idx in enumerate(tokens):\n", "        print(f\"{i+1}. {idx2word[idx]}\")"]}], "metadata": {"colab": {"name": "DeepGAN_Logframe"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 0}